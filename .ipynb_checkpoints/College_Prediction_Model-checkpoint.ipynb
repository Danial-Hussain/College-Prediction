{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# College Prediction Model\n",
    "**In this notebook we will be attempting to create a machine learning model that predicts acceptance or rejection into one of the top 15 universities in the United States**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing relevant libraries and then getting a glimpse of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('college_results_scrape.csv', encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision</th>\n",
       "      <th>SAT</th>\n",
       "      <th>ACT</th>\n",
       "      <th>Subject_tests</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Income_Bracket</th>\n",
       "      <th>School_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision: Deferred</td>\n",
       "      <td>SAT I (breakdown): 760R 800M</td>\n",
       "      <td>ACT (breakdown): 30E 34S 34R 34M</td>\n",
       "      <td>SAT II: 760 Chem</td>\n",
       "      <td>GPA (out of 4.0): n/a</td>\n",
       "      <td>Top 10%</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision: DeferredObjective:</td>\n",
       "      <td>SAT I (breakdown): N/A</td>\n",
       "      <td>ACT (breakdown): 35 C (35 E, 33 M, 35 R, 36 S)</td>\n",
       "      <td>SAT II: 800 Math II, 740 Chemistry, 720 World ...</td>\n",
       "      <td>GPA (out of 4.0): 4.0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>F</td>\n",
       "      <td>South asian</td>\n",
       "      <td>Income Bracket: 150k+</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision: Accepted</td>\n",
       "      <td>SAT I (breakdown): 800 Math, 760 Reading, 6/6/...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAT II: 780 Math II (sophomore year), 800 Phys...</td>\n",
       "      <td>GPA (out of 4.0): 4.0</td>\n",
       "      <td>Top 10%</td>\n",
       "      <td>Female</td>\n",
       "      <td>White</td>\n",
       "      <td>Income Bracket: Upper Middle Class</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Decision: Deferred</td>\n",
       "      <td>SAT I (breakdown): 1530 (740 EBRW 790 Math)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAT II: 720 Chemistry, 720 Math I</td>\n",
       "      <td>GPA (out of 4.0): 4.0</td>\n",
       "      <td>Top 10%</td>\n",
       "      <td>Male</td>\n",
       "      <td>White</td>\n",
       "      <td>Income Bracket: &gt;$150k</td>\n",
       "      <td>Public</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision: Deferred</td>\n",
       "      <td>SAT I (breakdown): 1580 (Math 800, Reading 780)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SAT II: 800 Math, 800 Physics</td>\n",
       "      <td>GPA (out of 4.0): 4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Male</td>\n",
       "      <td>N</td>\n",
       "      <td>Income Bracket: Too much</td>\n",
       "      <td>Large, competitive, public</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Decision  \\\n",
       "0            Decision: Deferred   \n",
       "1  Decision: DeferredObjective:   \n",
       "2            Decision: Accepted   \n",
       "3            Decision: Deferred   \n",
       "4            Decision: Deferred   \n",
       "\n",
       "                                                 SAT  \\\n",
       "0                       SAT I (breakdown): 760R 800M   \n",
       "1                             SAT I (breakdown): N/A   \n",
       "2  SAT I (breakdown): 800 Math, 760 Reading, 6/6/...   \n",
       "3        SAT I (breakdown): 1530 (740 EBRW 790 Math)   \n",
       "4    SAT I (breakdown): 1580 (Math 800, Reading 780)   \n",
       "\n",
       "                                              ACT  \\\n",
       "0                ACT (breakdown): 30E 34S 34R 34M   \n",
       "1  ACT (breakdown): 35 C (35 E, 33 M, 35 R, 36 S)   \n",
       "2                                             NaN   \n",
       "3                                             NaN   \n",
       "4                                             NaN   \n",
       "\n",
       "                                       Subject_tests                    GPA  \\\n",
       "0                                   SAT II: 760 Chem  GPA (out of 4.0): n/a   \n",
       "1  SAT II: 800 Math II, 740 Chemistry, 720 World ...  GPA (out of 4.0): 4.0   \n",
       "2  SAT II: 780 Math II (sophomore year), 800 Phys...  GPA (out of 4.0): 4.0   \n",
       "3                  SAT II: 720 Chemistry, 720 Math I  GPA (out of 4.0): 4.0   \n",
       "4                      SAT II: 800 Math, 800 Physics  GPA (out of 4.0): 4.0   \n",
       "\n",
       "      Rank   Gender     Ethnicity                      Income_Bracket  \\\n",
       "0  Top 10%      NaN           NaN                                 NaN   \n",
       "1      N/A        F   South asian               Income Bracket: 150k+   \n",
       "2  Top 10%   Female         White  Income Bracket: Upper Middle Class   \n",
       "3  Top 10%     Male         White              Income Bracket: >$150k   \n",
       "4      NaN     Male             N            Income Bracket: Too much   \n",
       "\n",
       "                   School_Type  \n",
       "0                          NaN  \n",
       "1                       Public  \n",
       "2                       Public  \n",
       "3                       Public  \n",
       "4   Large, competitive, public  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing- Cleaning Stage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Column Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are attempting to remove the \"Decision\" before each result in the Decision column. We will also be unifying all the results to either Accepted or Rejected. For this project we will be considering deferrals and waitlists as rejections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision = data.loc[:, 'Decision']\n",
    "#Cleaning the Decision column\n",
    "for row in range(len(decision)):\n",
    "    #We will consider deferrals and waitlists as rejections\n",
    "    if decision[row].find(\"Deferred\") != -1 or decision[row].find(\"DEFERRAL\") != -1:\n",
    "        decision[row] = decision[row].replace(decision[row],'Rejected')\n",
    "        \n",
    "    if decision[row].find('Wait') != -1 or decision[row].find('wait') != -1:\n",
    "        decision[row] = decision[row].replace(decision[row],'Rejected')\n",
    "    \n",
    "    if decision[row].find('Reject') != -1:\n",
    "        decision[row] = decision[row].replace(decision[row],'Rejected')\n",
    "          \n",
    "    if decision[row].find(\"Accepted\") != -1 or decision[row].find(\"ACCEPTED\") != -1 or decision[row].find(\"AdMITted\") != -1:\n",
    "        decision[row] = decision[row].replace(decision[row] ,'Accepted')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SAT Column Cleaning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are trying to remove the extraneous text in each row under the SAT column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing extra text and just grabbing SAT score\n",
    "import re\n",
    "SAT = data.loc[:, 'SAT']\n",
    "SAT = SAT.astype(str)\n",
    "regex = \"\\d{4}\"\n",
    "for row in range(len(SAT)):\n",
    "    match= re.findall(regex, SAT[row])\n",
    "    match = \"\".join(match)\n",
    "    if len(match) == 4:\n",
    "        SAT[row] = SAT[row].replace(SAT[row], match)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combining data that is given in SAT subscores\n",
    "rege = \"\\d{3}\"\n",
    "for row in range(len(SAT)):\n",
    "    tot = re.findall(rege, SAT[row])\n",
    "    tot = \"\".join(tot)\n",
    "    if len(tot) == 6:\n",
    "        tot = int(tot[0:3]) + int(tot[3:6])\n",
    "        tot = str(tot)\n",
    "        SAT[row] = SAT[row].replace(SAT[row], tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting all nan values in the SAT column to 0\n",
    "for row in range(len(SAT)):\n",
    "    if SAT[row].find(\"SAT I\") != -1 or SAT[row].find(\"nan\") != -1:\n",
    "        SAT[row] = SAT[row].replace(SAT[row], '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SAT'] = SAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ACT Column Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dictionary to map ACT scores to SAT scores\n",
    "act_to_sat = {'36': '1600', '35': '1540', '34':'1500', '33': '1460', '32': '1430', '31': '1400', '30': '1370',\n",
    "              '29': '1340', '28': '1310', '27': '1280', '26': '1240', '25': '1210', '24': '1180', '23': '1140',\n",
    "              '22': '1110', '21' : '1080', '20':'1040', '0': '0', 'nan': '0'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACT = data.loc[:, 'ACT']\n",
    "ACT = ACT.astype(str)\n",
    "digit = \"\\d{2}\"\n",
    "#Extracting composite scores\n",
    "for row in range(len(ACT)):\n",
    "    total = re.findall(digit, ACT[row])\n",
    "    total = \"\".join(total)\n",
    "    if len(total) == 2:        \n",
    "        ACT[row] = ACT[row].replace(ACT[row], total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Averaging subscores to find composite\n",
    "for row in range(len(ACT)):\n",
    "    total = re.findall(digit, ACT[row])\n",
    "    total = \"\".join(total)\n",
    "    if len(total) == 8:\n",
    "        total = int((int(total[0:2]) + int(total[2:4]) + int(total[4:6]) + int(total[6:8]))/4)\n",
    "        total = str(total)\n",
    "        ACT[row] = ACT[row].replace(ACT[row], total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Averaging subscores to find composite\n",
    "for row in range(len(ACT)):\n",
    "    total = re.findall(digit, ACT[row])\n",
    "    total = \"\".join(total)\n",
    "    if len(total) == 10:\n",
    "        total = int((int(total[0:2]) + int(total[2:4]) + int(total[4:6]) + int(total[6:8]) + int(total[8:10]))/5)\n",
    "        total = str(total)\n",
    "        ACT[row] = ACT[row].replace(ACT[row], total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dealing with nan values in ACT column\n",
    "for row in range(len(ACT)):\n",
    "    if ACT[row].find(\"ACT\") != -1:\n",
    "        ACT[row] = ACT[row].replace(ACT[row], '0')\n",
    "data['ACT'] = ACT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I will convert all ACT scores to SAT scores and then merge the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(ACT)):\n",
    "    ACT[row] = ACT[row].replace(ACT[row], act_to_sat[ACT[row]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ACT'] = ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(SAT)):\n",
    "    if int(SAT[row]) > int(ACT[row]):\n",
    "        pass\n",
    "    if int(SAT[row]) < int(ACT[row]):\n",
    "        SAT[row] = ACT[row]\n",
    "data['SAT'] = SAT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Subject Test Column Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_tests= ['0'] * 383\n",
    "Subject_tests = data.loc[:, 'Subject_tests']\n",
    "Subject_tests = Subject_tests.astype(str)\n",
    "calc = \"\\d{3}\"\n",
    "#Removing all text and only leaving scores\n",
    "for row in range(len(Subject_tests)):\n",
    "    total = re.findall(calc, Subject_tests[row])\n",
    "    total = \"\".join(total)\n",
    "    Subject_tests[row] = Subject_tests[row].replace(Subject_tests[row], total)\n",
    "    num_tests[row] = str(len(total)/3)\n",
    "num_tests_col = pd.Series(num_tests)\n",
    "\n",
    "#Creating a new column to keep track of the number of subject tests taken\n",
    "data['number_of_subject_tests'] = num_tests_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(Subject_tests)):\n",
    "    length = len(Subject_tests[row])\n",
    "    #Averaging the scores depending on the number of tests taken\n",
    "    if length == 6:\n",
    "        dat = Subject_tests[row]\n",
    "        total = str(int(dat[0:3]) + int(dat[3:6]))\n",
    "        Subject_tests[row] = Subject_tests[row].replace(Subject_tests[row], str(int(total)/(length/3)))\n",
    "    if length == 9:\n",
    "        dat = Subject_tests[row]\n",
    "        total = str(int(dat[0:3]) + int(dat[3:6]) + int(dat[6:9]))\n",
    "        Subject_tests[row] = Subject_tests[row].replace(Subject_tests[row], str(int(total)/(length/3)))\n",
    "    if length == 12:\n",
    "        dat = Subject_tests[row]\n",
    "        total = str(int(dat[0:3]) + int(dat[3:6]) + int(dat[6:9]) + int(dat[9:12]))\n",
    "        Subject_tests[row] = Subject_tests[row].replace(Subject_tests[row], str(int(total)/(length/3)))\n",
    "    if length == 15:\n",
    "        dat = Subject_tests[row]\n",
    "        total = str(int(dat[0:3]) + int(dat[3:6]) + int(dat[6:9]) + int(dat[9:12]) + int(dat[12:15]))\n",
    "        Subject_tests[row] = Subject_tests[row].replace(Subject_tests[row], str(int(total)/(length/3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Subject_tests'] = Subject_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GPA Column Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPA = data.loc[:, 'GPA']\n",
    "GPA = GPA.astype(str)\n",
    "for row in range(len(GPA)):\n",
    "    GPA[row] = GPA[row].replace(\"GPA (out of 4.0):\", \"\")\n",
    "    temp = re.findall('\\d*\\.?\\d+', GPA[row])\n",
    "    temp = \"\".join(temp)\n",
    "    GPA[row] = GPA[row].replace(GPA[row], temp)\n",
    "data['GPA'] = GPA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rank Column Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank = data.loc[:, 'Rank']\n",
    "Rank = Rank.astype(str)\n",
    "for row in range (len(Rank)):\n",
    "    if Rank[row].find('Top 10%') == -1 and Rank[row].find(\"Not Top 10%\") == -1:\n",
    "        Rank[row] = Rank[row].replace(Rank[row], 'NA')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Rank'] = Rank"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gender Column Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gender = data.loc[:, 'Gender']\n",
    "Gender = Gender.astype(str)\n",
    "for row in range(len(Gender)):\n",
    "    if Gender[row].find('f') != -1 or Gender[row].find('F') != -1:\n",
    "        Gender[row] = Gender[row].replace(Gender[row], 'F')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(Gender)):\n",
    "    if Gender[row].find('m') != -1 or Gender[row].find('M') != -1:\n",
    "        Gender[row] = Gender[row].replace(Gender[row], 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in range(len(Gender)):\n",
    "    if Gender[row].find('M') == -1 and Gender[row].find('F') == -1:\n",
    "        Gender[row] = Gender[row].replace(Gender[row], 'NA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Gender'] = Gender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ethnicity Column Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ethnicity = data.loc[:, 'Ethnicity']\n",
    "Ethnicity = Ethnicity.astype(str)\n",
    "for row in range(len(Ethnicity)):\n",
    "    if Ethnicity[row].find('exican') != -1 or Ethnicity[row].find('hispanic') != -1 or Ethnicity[row].find('ispanic') != -1 or Ethnicity[row].find('frican') != -1 or Ethnicity[row].find('atin') != -1 or Ethnicity[row].find('ative') != -1:\n",
    "        Ethnicity[row] = Ethnicity[row].replace(Ethnicity[row], 'Minority')\n",
    "\n",
    "for row in range(len(Ethnicity)):\n",
    "    if Ethnicity[row].find('Minority') == -1:\n",
    "        Ethnicity[row] = Ethnicity[row].replace(Ethnicity[row], 'Not Minority')\n",
    "\n",
    "data['Ethnicity'] = Ethnicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**School Type Column Cleaning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "School = data.loc[:, 'School_Type']\n",
    "School = School.astype(str)\n",
    "for row in range(len(School)):\n",
    "    if School[row].find('ublic') != -1 or School[row].find('harter') != -1:\n",
    "        School[row] = School[row].replace(School[row], 'Public')\n",
    "for row in range(len(School)):\n",
    "    if School[row].find('rivate') != -1 or School[row].find('oarding') != -1:\n",
    "        School[row] = School[row].replace(School[row], 'Private')\n",
    "for row in range(len(School)):\n",
    "    if School[row].find('ome') != -1:\n",
    "        School[row] = School[row].replace(School[row], 'Home')\n",
    "for row in range(len(School)):\n",
    "    if School[row].find('Public') == -1 and School[row].find('Private') == -1 and School[row].find('Home') == -1:\n",
    "        School[row] = School[row].replace(School[row], 'Public')\n",
    "data['School_Type'] = School"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Decision</th>\n",
       "      <th>SAT</th>\n",
       "      <th>ACT</th>\n",
       "      <th>Subject_tests</th>\n",
       "      <th>GPA</th>\n",
       "      <th>Rank</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Ethnicity</th>\n",
       "      <th>Income_Bracket</th>\n",
       "      <th>School_Type</th>\n",
       "      <th>number_of_subject_tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>1560</td>\n",
       "      <td>1460</td>\n",
       "      <td>760</td>\n",
       "      <td></td>\n",
       "      <td>Top 10%</td>\n",
       "      <td>NA</td>\n",
       "      <td>Not Minority</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Public</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>745.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>F</td>\n",
       "      <td>Not Minority</td>\n",
       "      <td>Income Bracket: 150k+</td>\n",
       "      <td>Public</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accepted</td>\n",
       "      <td>1560</td>\n",
       "      <td>0</td>\n",
       "      <td>793.3333333333334</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Top 10%</td>\n",
       "      <td>F</td>\n",
       "      <td>Not Minority</td>\n",
       "      <td>Income Bracket: Upper Middle Class</td>\n",
       "      <td>Public</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Top 10%</td>\n",
       "      <td>M</td>\n",
       "      <td>Not Minority</td>\n",
       "      <td>Income Bracket: &gt;$150k</td>\n",
       "      <td>Public</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>1580</td>\n",
       "      <td>0</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>M</td>\n",
       "      <td>Not Minority</td>\n",
       "      <td>Income Bracket: Too much</td>\n",
       "      <td>Public</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>Accepted</td>\n",
       "      <td>1460</td>\n",
       "      <td>1460</td>\n",
       "      <td></td>\n",
       "      <td>3.93</td>\n",
       "      <td>Top 10%</td>\n",
       "      <td>F</td>\n",
       "      <td>Not Minority</td>\n",
       "      <td>Income Bracket: $175,000~</td>\n",
       "      <td>Private</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>Accepted</td>\n",
       "      <td>1400</td>\n",
       "      <td>1400</td>\n",
       "      <td></td>\n",
       "      <td>4.0</td>\n",
       "      <td>Top 10%</td>\n",
       "      <td>F</td>\n",
       "      <td>Not Minority</td>\n",
       "      <td>Income Bracket: 200,000+</td>\n",
       "      <td>Public</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>380</th>\n",
       "      <td>Rejected</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td></td>\n",
       "      <td>3.76</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>Not Minority</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Public</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>Accepted</td>\n",
       "      <td>1540</td>\n",
       "      <td>1540</td>\n",
       "      <td>760.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>M</td>\n",
       "      <td>Not Minority</td>\n",
       "      <td>Income Bracket:</td>\n",
       "      <td>Public</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>Accepted</td>\n",
       "      <td>1430</td>\n",
       "      <td>1430</td>\n",
       "      <td></td>\n",
       "      <td>3.97</td>\n",
       "      <td>Not Top 10%</td>\n",
       "      <td>F</td>\n",
       "      <td>Not Minority</td>\n",
       "      <td>Income Bracket: $100,000+</td>\n",
       "      <td>Private</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>383 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Decision   SAT   ACT      Subject_tests   GPA         Rank Gender  \\\n",
       "0    Rejected  1560  1460                760            Top 10%     NA   \n",
       "1    Rejected  1500  1500              745.0   4.0           NA      F   \n",
       "2    Accepted  1560     0  793.3333333333334   4.0      Top 10%      F   \n",
       "3    Rejected  1530     0              720.0   4.0      Top 10%      M   \n",
       "4    Rejected  1580     0              800.0   4.0           NA      M   \n",
       "..        ...   ...   ...                ...   ...          ...    ...   \n",
       "378  Accepted  1460  1460                     3.93      Top 10%      F   \n",
       "379  Accepted  1400  1400                      4.0      Top 10%      F   \n",
       "380  Rejected  1500  1500                     3.76           NA     NA   \n",
       "381  Accepted  1540  1540              760.0   4.0           NA      M   \n",
       "382  Accepted  1430  1430                     3.97  Not Top 10%      F   \n",
       "\n",
       "        Ethnicity                      Income_Bracket School_Type  \\\n",
       "0    Not Minority                                 NaN      Public   \n",
       "1    Not Minority               Income Bracket: 150k+      Public   \n",
       "2    Not Minority  Income Bracket: Upper Middle Class      Public   \n",
       "3    Not Minority              Income Bracket: >$150k      Public   \n",
       "4    Not Minority            Income Bracket: Too much      Public   \n",
       "..            ...                                 ...         ...   \n",
       "378  Not Minority           Income Bracket: $175,000~     Private   \n",
       "379  Not Minority            Income Bracket: 200,000+      Public   \n",
       "380  Not Minority                                 NaN      Public   \n",
       "381  Not Minority                     Income Bracket:      Public   \n",
       "382  Not Minority           Income Bracket: $100,000+     Private   \n",
       "\n",
       "    number_of_subject_tests  \n",
       "0                       1.0  \n",
       "1                       4.0  \n",
       "2                       3.0  \n",
       "3                       2.0  \n",
       "4                       2.0  \n",
       "..                      ...  \n",
       "378                     0.0  \n",
       "379                     0.0  \n",
       "380                     0.0  \n",
       "381                     2.0  \n",
       "382                     0.0  \n",
       "\n",
       "[383 rows x 11 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the SAT column we will use the mean for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SAT'] = pd.to_numeric(data['SAT'])\n",
    "data['SAT'].replace(0, np.nan, inplace = True)\n",
    "data['SAT'].replace(300., np.nan, inplace= True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the subject tests column we will replace nan values with zero, since the Subject tests are optional in the admissions process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Subject_tests'].replace(\"\", np.nan, inplace = True)\n",
    "data['Subject_tests'] = pd.to_numeric(data['Subject_tests'])\n",
    "data['Subject_tests'].replace(np.nan, 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the GPA column we will replace nan values with the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['GPA'].replace('', np.nan, inplace = True)\n",
    "data['GPA'] = pd.to_numeric(data['GPA'])\n",
    "data['GPA'].replace(4.33, 4.0, inplace = True)\n",
    "data['GPA'].replace(4.55, 4.0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing Nan values in Rank with the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Rank'].replace(\" Not Top 10%\", 'Not Top 10%', inplace = True)\n",
    "data['Rank'].replace(\"NA\", 'Top 10%', inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making # of subject tests cell to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['number_of_subject_tests'] = pd.to_numeric(data['number_of_subject_tests'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependent variable\n",
    "y = data.Decision\n",
    "#Independent variable\n",
    "X = data\n",
    "X.drop(columns = ['ACT', 'Income_Bracket'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Break off validation set from training data\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,\n",
    "                                                                random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pipeline: Target encoding the categorical variables and numerical variables\n",
    "numerical_cols = ['SAT', 'GPA', 'number_of_subject_tests']\n",
    "categorical_cols = ['Rank', 'Gender', 'Ethnicity', 'School_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.43410348021386985\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Preprocessing for numerical data\n",
    "numerical_transformer = SimpleImputer(strategy='mean')\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "model = XGBRegressor(n_estimators = 1000, learning_rate =0.05)\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)\n",
    "                     ])\n",
    "\n",
    "#One-hot encoding the y variable\n",
    "labelencoder_Y = LabelEncoder()\n",
    "y_train = labelencoder_Y.fit_transform(y_train)\n",
    "y_valid = labelencoder_Y.fit_transform(y_valid)\n",
    "\n",
    "# Preprocessing of training data, fit model \n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Preprocessing of validation data, get predictions\n",
    "preds = clf.predict(X_valid)\n",
    "print('MAE:', mean_absolute_error(y_valid, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Top 10%'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-f2a997159cc9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnew_input\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1540\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3.85\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Top 10%'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'M'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Not Minority'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Public'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnew_ouput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\alida\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 766\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alida\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\alida\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X, check_input)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \u001b[1;34m\"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m             if issparse(X) and (X.indices.dtype != np.intc or\n\u001b[0;32m    382\u001b[0m                                 X.indptr.dtype != np.intc):\n",
      "\u001b[1;32mc:\\users\\alida\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32mc:\\users\\alida\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'Top 10%'"
     ]
    }
   ],
   "source": [
    "new_input= [[1540, 0, 3.85, 'Top 10%', 'M', 'Not Minority', 'Public', 0]]\n",
    "new_ouput = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
